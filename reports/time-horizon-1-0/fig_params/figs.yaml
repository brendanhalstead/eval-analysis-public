# Comparison colors for overlay/comparison plots
comparison_color_1: "#56B4E9"
comparison_color_2: "#E69F00"

exclude_agents: &exclude_agents
  - GPT-4 0125
  - DeepSeek-R1-0528
  - DeepSeek-V3-0324
  - DeepSeek-R1
  - DeepSeek-V3
  - Qwen2.5-72B
  - Qwen2-72B
  - o4-mini
  - Claude Sonnet 4.5
  - Claude 4 Opus
  - Claude 4 Sonnet
  - Claude 3 Opus
  - GPT-4 Turbo
  - Kimi K2 Thinking
  - gpt-oss-120b
  - Gemini 2.5 Pro Preview

exclude_agents_from_all_fits: &exclude_agents_from_all_fits
  - Claude Sonnet 4.5
  - Claude 4 Opus
  - Claude 4 Sonnet
  - Claude 3 Opus
  - o4-mini
  - GPT-4 Turbo
  - DeepSeek-R1-0528
  - DeepSeek-V3-0324
  - DeepSeek-R1
  - DeepSeek-V3
  - Qwen2.5-72B
  - Qwen2-72B
  - Kimi K2 Thinking
  - gpt-oss-120b
  - Gemini 2.5 Pro Preview

default_agents: &default_agents
  - GPT-5.1-Codex-Max
  - GPT-5
  - Grok 4
  - Claude Opus 4.5
  - Claude 4.1 Opus
  - Claude 3.7 Sonnet
  - Claude 3.5 Sonnet (New)
  - Claude 3.5 Sonnet (Old)
  - Claude 3 Opus
  - o4-mini
  - o3
  - o1
  - o1-preview
  - GPT-4o
  - GPT-4 Turbo
  - GPT-4 1106
  - GPT-4 0314
  - gpt-3.5-turbo-instruct
  - davinci-002 (GPT-3)
  - GPT-2

horizon_exclude_agents_with_human: &horizon_exclude_agents_with_human
  - GPT-4 0125
  - DeepSeek-R1-0528
  - DeepSeek-V3-0324
  - DeepSeek-R1
  - DeepSeek-V3
  - Qwen2.5-72B
  - Qwen2-72B
  - o4-mini
  - Claude Sonnet 4.5
  - Claude 4.1 Opus
  - Claude 4 Opus
  - Claude 4 Sonnet
  - Claude 3 Opus
  - GPT-4 Turbo
  - human

figs:
  wrangle_logistic:
    headline: &wrangle_headline
      runs_file: &runs_file data/raw/runs.jsonl
      weighting: invsqrt_task_weight
      categories: ftr
      regularization: 0.1
      exclude: []
      success_percents: [50, 80]
      confidence_level: 0.95

    partial_scoring:
      <<: *wrangle_headline
      score_col: score_cont

    ga_rebench:
      <<: *wrangle_headline
      exclude: ["SWAA"]
      success_percents: [50]

  plot_bar_chart_weighted_scores:
    focus_agents: *default_agents
    weighting: "invsqrt_task_weight"
    exclude: []

  plot_bar_chart:
    bar_chart_agents_ordered:
      - GPT-4 Turbo
      - Claude 3 Opus
      - GPT-4o
      - Claude 3.5 Sonnet (Old)
      - o1-preview
      - Claude 3.5 Sonnet (New)
      - o1
      - Claude 3.7 Sonnet

    bar_chart_highlight_agent: "Claude 3.7 Sonnet"

  plot_individual_histograms:
    default: &default_histogram
      annotate_p50: true
      logistic_file: "data/wrangled/logistic_fits/headline.csv"
      weighting: "invsqrt_task_weight"
      title: "Success probabilities at different task lengths"
      n_subplot_cols: 3
      horizontal_lines:
        - p_success: 0.5
          styling:
            color: "firebrick"
            linestyle: "dashed"
            linewidth: 1.8
            alpha: 0.7
      x_lim_start: "2022-12-01"
      x_lim_end: "2025-04-01"
      lower_y_lim: 0
      upper_y_lim: 1
      exclude: []
      include_agents: *default_agents

    overlaid:
      <<: *default_histogram
      n_subplot_cols: 1
      title: "Models are succeeding at increasingly long tasks"
      include_agents:
        - Claude 3.7 Sonnet
        - o1-preview
        - GPT-4 0314
        - gpt-3.5-turbo-instruct
        - davinci-002 (GPT-3)
        - GPT-2
      annotate_p50: false
      type: "overlaid"

  plot_logistic_regression:
    headline: &plot_headline
      <<: *wrangle_headline
      trendlines:
        - fit_type: exponential
          caption: null
          after_date: "2019-01-01"
          color: blue
          line_start_date: "2018-09-03"
          line_end_date: "2027-01-01"
          exclude_agents: *exclude_agents_from_all_fits
          display_r_squared: true
          styling: null
          data_file: null
          skip_annotation: false
      include_task_distribution: none
      individual_labels: true
      x_lim_start: "2018-09-03"
      x_lim_end: "2027-01-01"
      exclude_agents_from_all_fits: *exclude_agents_from_all_fits # for bootstrap_ci.py only
      lower_y_lim: 0.0083333 # 0.5 seconds
      upper_y_lim: 360
      linear_overrides:
        show_minor_xticks: false
        lower_y_lim: 0
        plot_style_overrides:
          scatter_styling:
            error_bar:
              alpha: 0.5
              capsize: 0
      exclude_agents: *exclude_agents
      title: "Length of tasks AI agents have been able to complete autonomously"
      subtitle: "for 169 software engineering, cybersecurity, general reasoning, and ML tasks"
      rename_legend_labels:
        "davinci-002 (GPT-3)": "GPT 3"
        "gpt-3.5-turbo-instruct": "GPT 3.5"
        "GPT-4o": "GPT 4o"
        "Claude Sonnet 4.5": "Sonnet 4.5"
        "Claude 4.1 Opus": "Opus 4.1"
        "Claude 4 Opus": "Opus 4"
        "Claude 4 Sonnet": "Sonnet 4"
        "Claude 3.7 Sonnet": "Sonnet 3.7"
        "Claude 3.5 Sonnet (New)": "Sonnet 3.6"
        "Claude 3.5 Sonnet (Old)": "Sonnet 3.5"
        "Claude 3 Opus": "Claude 3"
        "GPT-5.1-Codex-Max": "GPT-5.1-Codex-Max"
        "o3": "o3"
        "o4-mini": "o4-mini"
        "o1": "o1"
        "o1-preview": "o1 preview"
        "GPT-5": "GPT-5"
        "Grok 4": "Grok 4"
        "GPT-4 Turbo": "GPT-4 Turbo"
        "GPT-4 1106": "GPT-4 Nov '23"
        "GPT-4 0314": "GPT-4"
        "GPT-2": "GPT-2"
        "gpt-oss-120b": "gpt-oss-120b"
        "Gemini 2.5 Pro Preview": "Gemini 2.5 Pro Preview"
        "Kimi K2 Thinking": "Kimi K2 Thinking\n(inference via Novita AI)"
      show_y_label: true
    twitter_headline: &twitter_headline
      <<: *plot_headline
      title: "Claude Opus 4.5 has a 50%-time horizon of about 4 hrs 49 min (95% CI: 109 to 1225 min)"
      subtitle: "Task length (at 50% success rate)"
      title_location: "left"
      suptitle_location: "left"
      legend_fontsize: 14
      ax_label_fontsize: 14
      title_fontsize: 14
      xlabel: "Model release date"
      ylabel: ""
      upper_y_lim: 1560 # 26 hours. Units: minutes
      show_grid: true
      y_ticks_skip: 2
      hide_regression_info: false
      annotation_fontsize: 14
      legend_frameon: false
      xticks_skip: 2
      show_watermark: true
      show_example_tasks: true
      show_minor_xticks: true
      linear_overrides:
        show_minor_xticks: false
        hide_error_bars: false
        hide_trendline: true
        show_example_tasks: false
        lower_y_lim: 0
        y_ticks_skip: 1
        plot_style_overrides:
          scatter_styling:
            error_bar:
              alpha: 0.5
              capsize: 0
      plot_style_overrides:
        scatter_styling:
          scatter:
            s: 75
        agent_styling:
          "Claude Opus 4.5":
            lab_color: &metr_green "#2c7c58"
            marker: "o"
            unique_color: "#c86592"
          "Claude Sonnet 4.5":
            lab_color: &metr_gray "#A0A0A0"
            marker: "o"
          "Claude 4.1 Opus":
            lab_color: *metr_green
            marker: "o"
          "Claude 4 Opus":
            lab_color: *metr_gray
            marker: "o"
          "Claude 4 Sonnet":
            lab_color: *metr_gray
            marker: "o"
          "Qwen2-72B":
            lab_color: *metr_green
            marker: "o"
          "Qwen2.5-72B":
            lab_color: *metr_green
            marker: "o"
          "DeepSeek-V3":
            lab_color: *metr_green
            marker: "o"
          "DeepSeek-R1":
            lab_color: *metr_green
            marker: "o"
          "DeepSeek-V3-0324":
            lab_color: *metr_green
            marker: "o"
          "DeepSeek-R1-0528":
            lab_color: *metr_gray
            marker: "o"
          "GPT-5.1-Codex-Max":
            lab_color: *metr_green
            marker: "o"
          "o3":
            lab_color: *metr_green
            marker: "o"
          "o4-mini":
            lab_color: *metr_gray
            marker: "o"
          "Claude 3.7 Sonnet":
            lab_color: *metr_green
            marker: "o"
          "Claude 3.5 Sonnet (New)":
            lab_color: *metr_green
            marker: "o"
          "Claude 3.5 Sonnet (Old)":
            lab_color: *metr_green
            marker: "o"
          "Claude 3 Opus":
            lab_color: *metr_gray
            marker: "o"
          "o1":
            lab_color: *metr_green
            marker: "o"
          "o1-preview":
            lab_color: *metr_green
            marker: "o"
          "GPT-4o":
            lab_color: *metr_green
            marker: "o"
          "GPT-4 Turbo":
            lab_color: *metr_gray
            marker: "o"
          "GPT-4 0125":
            lab_color: *metr_green
            marker: "o"
          "GPT-4 1106":
            lab_color: *metr_green
            marker: "o"
          "GPT-4 0314":
            lab_color: *metr_green
            marker: "o"
          "gpt-3.5-turbo-instruct":
            lab_color: *metr_green
            marker: "o"
          "davinci-002 (GPT-3)":
            lab_color: *metr_green
            marker: "o"
          "GPT-2":
            lab_color: *metr_green
            marker: "o"
          "gpt-oss-120b":
            lab_color: *metr_green
            marker: "o"
          "Gemini 2.5 Pro Preview":
            lab_color: *metr_green
            marker: "o"
          "GPT-5":
            lab_color: *metr_green
            marker: "s"
            unique_color: *metr_green
          "Grok 4":
            lab_color: *metr_green
            marker: "D"
            unique_color: "#000000"
          "human":
            lab_color: "grey"
            marker: "o"
            unique_color: "#858585"
          "default":
            lab_color: "black"
            marker: "o"
            unique_color: "black"
      individual_labels: true
      show_y_label: false
    twitter_headline_inspect_overlay:
      <<: *twitter_headline
      title: "Time Horizon 1.0 vs Time Horizon 1.1 (augmented trend)"
      overlay_results: "../time-horizon-1-1/metrics/benchmark_results.yaml"
    twitter_headline_from_2023_inspect_overlay:
      <<: *twitter_headline
      title: "Time Horizon 1.0 vs Time Horizon 1.1"
      x_lim_start: "2022-12-01"
      show_example_tasks: false
      overlay_results: "../time-horizon-1-1/metrics/benchmark_results.yaml"
      trendlines:
        - fit_type: exponential
          caption: null
          after_date: "2023-03-14"
          color: blue
          line_start_date: "2023-03-14"
          line_end_date: "2027-01-01"
          exclude_agents: *exclude_agents_from_all_fits
          display_r_squared: true
          styling: null
          data_file: null
          skip_annotation: false
    p80:
      <<: *plot_headline
      logistic_file: headline
      subtitle: 80% success rate
      success_percent: 80
      trendlines:
        - fit_type: exponential
          caption: null
          after_date: "2020-01-01"
          color: blue
          line_start_date: "2019-09-01"
          line_end_date: "2027-01-01"
          exclude_agents: *exclude_agents_from_all_fits
          display_r_squared: true
          styling: null
          data_file: null
          skip_annotation: false
        - fit_type: exponential
          caption: null
          after_date: "2020-01-01"
          color: grey
          line_start_date: "2019-09-01"
          line_end_date: "2027-01-01"
          exclude_agents: *exclude_agents_from_all_fits
          display_r_squared: true
          success_percent: 50
          data_file: null
          skip_annotation: true
          styling:
            linestyle: dashed
      exclude_agents: *exclude_agents

    single_line_2023_ga_rebench:
      runs_file: *runs_file
      logistic_file: ga_rebench
      trendlines:
        - fit_type: exponential
          skip_annotation: false
          caption: null
          after_date: "2023-01-01"
          color: blue
          line_start_date: "2023-01-01"
          line_end_date: "2025-04-01"
          exclude_agents: *exclude_agents_from_all_fits
          display_r_squared: true
          data_file: null
          styling:
            linewidth: 2
            alpha: 0.5
            linestyle: dashed
      include_task_distribution: none
      weighting: invsqrt_task_weight
      x_lim_start: "2022-12-01"
      x_lim_end: "2025-04-01"
      lower_y_lim: 1
      upper_y_lim: 90
      exclude:
        - SWAA
      exclude_agents: *exclude_agents
      show_y_label: true

    double_line_all_data_retrodict_excluding_swaa:
      runs_file: *runs_file
      logistic_file: headline
      weighting: invsqrt_task_weight
      include_task_distribution: none
      title: "50% Time Horizon Retrodicted from 2023-2025 Data"

      trendlines:
        - fit_type: exponential
          skip_annotation: false
          caption: Fit on all data
          after_date: "2019-01-01"
          color: black
          line_start_date: "2018-09-03"
          line_end_date: "2025-07-01"
          exclude_agents: *exclude_agents_from_all_fits
          display_r_squared: false
          data_file: null
          styling:
            linewidth: 2
            alpha: 0.6
            linestyle: solid
        - fit_type: exponential
          skip_annotation: false
          caption: |-
            Fit on non-SWAA tasks, 2023-2025 models
          after_date: "2023-01-01"
          color: blue
          line_start_date: "2018-09-03"
          line_end_date: "2025-07-01"
          display_r_squared: false
          data_file: data/wrangled/logistic_fits/ga_rebench.csv
          styling:
            linewidth: 2
            alpha: 0.6
            linestyle: solid
      exclude: []
      exclude_agents: *exclude_agents
      lower_y_lim: 0.0083333 # 0.5 seconds
      upper_y_lim: 240
      x_lim_start: "2018-09-03"
      x_lim_end: "2025-11-06"
      show_y_label: true

    double_line_2023_trendline:
      <<: *plot_headline
      logistic_file: headline
      title: "2019-2025 and 2023-2025 Trendlines in 50% Time Horizon"
      trendlines:
        - fit_type: exponential
          caption: null
          after_date: "2019-01-01"
          color: blue
          line_end_date: "2027-01-01"
          data_file: null
        - fit_type: exponential
          caption: null
          after_date: "2023-01-01"
          color: red
          line_end_date: "2027-01-01"
          data_file: null

    partial_scoring:
      <<: *plot_headline
      logistic_file: partial_scoring
      subtitle: "Continuous Scoring"

    all_models:
      <<: *plot_headline
      logistic_file: headline
      exclude_agents: []

  compare_trend:
    exclude_agents: *exclude_agents
    exclude_agents_from_all_fits: *exclude_agents_from_all_fits
    confidence_level: 0.95

  plot_token_usage_distribution:
    token_range: [5000, 100000000]
    y_axis_max: 70
    n_bins: 50
    reference_lines: [250000, 500000, 1000000, 2000000, 5000000, 10000000]
    width_factor: 0.8
    time_buckets: ["1-4 min", "4-15 min", "15-60 min", "1-4 hr", "4hr+"]
    alias: "Claude Sonnet 4.5"

  wrangle_score_over_resource_horizon:
    generation_cost:
      x: generation_cost
      wrangle_params: ga_rebench
      score_column: score_binarized
      output: ga_rebench
      include_human_flag: "--include-human"
      exclude_agents: *horizon_exclude_agents_with_human
    tokens_count:
      x: tokens_count
      wrangle_params: ga_rebench
      score_column: score_binarized
      output: ga_rebench_tokens
      include_human_flag: ""
      exclude_agents: *horizon_exclude_agents_with_human

  plot_score_over_resource_horizon:
    linear_cost:
      y_scale: linear
      weighting_column: p50
      score_column: p50
      y_lim_lower: 0
      y_lim_upper: 145
      wrangled: ga_rebench
      output_file: ga_rebench_linear
      x: generation_cost
      exclude_agents: *horizon_exclude_agents_with_human
    log_cost:
      y_scale: log
      weighting_column: p50
      score_column: p50
      y_lim_lower: 0.70
      y_lim_upper: none
      wrangled: ga_rebench
      output_file: ga_rebench_log
      x: generation_cost
      exclude_agents: *horizon_exclude_agents_with_human
    linear_tokens:
      y_scale: linear
      weighting_column: p50
      score_column: p50
      y_lim_lower: 0
      y_lim_upper: 145
      wrangled: ga_rebench_tokens
      output_file: ga_rebench_tokens_linear
      x: tokens_count
      exclude_agents: *horizon_exclude_agents_with_human
    log_tokens:
      y_scale: log
      weighting_column: p50
      score_column: p50
      y_lim_lower: 0.70
      y_lim_upper: none
      wrangled: ga_rebench_tokens
      output_file: ga_rebench_tokens_log
      x: tokens_count
      exclude_agents: *horizon_exclude_agents_with_human
